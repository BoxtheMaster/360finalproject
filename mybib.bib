@inbook{FFM_intro,
 ISBN = {9781868145782},
 URL = {http://www.jstor.org/stable/10.18772/22013015782.21},
 abstract = {The emergence of the Five-Factor Model (FFM) of personality sparked an extensive amount of research in the area of personality theory and assessment. The FFM presents a structure for personality that is best described by five global domains or factors that characterise individual differences. These five domains are generally called Extraversion, Neuroticism, Openness to Experience, Agreeableness and Conscientiousness (Church, 2000; Costa & McCrae, 2008). This model is not based on any single theory of personality, and numerous factor analyses of existing personality instruments have returned very similar structures to that of the five factors (Allik & McCrae, 2004; McCrae, Terracciano & 79 Members},
 author = {N. Taylor and G. P. de Bruin},
 booktitle = {Psychological Assessment in South Africa: Research and applications},
 pages = {232--243},
 publisher = {Wits University Press},
 title = {The Basic Traits Inventory},
 year = {2013}
}

@article{merz_latent_2011,
	title = {A latent profile analysis of the Five Factor Model of personality: Modeling trait interactions},
	volume = {51},
	issn = {0191-8869},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3185358/},
	doi = {10.1016/j.paid.2011.07.022},
	shorttitle = {A latent profile analysis of the Five Factor Model of personality},
	abstract = {Interactions among the dimensions of the Five Factor Model ({FFM}) have not typically been evaluated in mental health research, with the extant literature focusing on bivariate relationships with psychological constructs of interest. This study used latent profile analysis to mimic higher-order interactions to identify homogenous personality profiles using the {FFM}, and also examined relationships between resultant profiles and affect, self-esteem, depression, anxiety, and coping efficacy. Participants (N = 371) completed self-report and daily diary questionnaires. A 3-profile solution provided the best fit to the data; the profiles were characterized as well-adjusted, reserved, and excitable. The well-adjusted group reported better psychological functioning in validation analyses. The reserved and excitable groups differed on anxiety, with the excitable group reporting generally higher anxiety than the reserved group. Latent profile analysis may be a parsimonious way to model personality heterogeneity.},
	pages = {915--919},
	number = {8},
	journaltitle = {Personality and individual differences},
	shortjournal = {Pers Individ Dif},
	author = {Merz, Erin L. and Roesch, Scott C.},
	urldate = {2021-04-24},
	date = {2011-12-01},
	pmid = {21984857},
	pmcid = {PMC3185358},
	file = {PubMed Central Full Text PDF:/Users/zepingluo/Zotero/storage/WH6JWXDU/Merz and Roesch - 2011 - A latent profile analysis of the Five Factor Model.pdf:application/pdf}
}

@article{gerlach_robust_2018,
	title = {A robust data-driven approach identifies four personality types across four large data sets},
	volume = {2},
	issn = {2397-3374},
	url = {http://www.nature.com/articles/s41562-018-0419-z},
	doi = {10.1038/s41562-018-0419-z},
	pages = {735--742},
	number = {10},
	journaltitle = {Nature Human Behaviour},
	shortjournal = {Nat Hum Behav},
	author = {Gerlach, Martin and Farb, Beatrice and Revelle, William and Nunes Amaral, Luís A.},
	urldate = {2021-04-24},
	date = {2018-10},
	langid = {english},
	file = {Gerlach et al. - 2018 - A robust data-driven approach identifies four pers.pdf:/Users/zepingluo/Zotero/storage/5PUBBENJ/Gerlach et al. - 2018 - A robust data-driven approach identifies four pers.pdf:application/pdf}
}

@article{hayat_unsupervised_2020,
	title = {Unsupervised Bayesian learning for rice panicle segmentation with {UAV} images},
	volume = {16},
	issn = {1746-4811},
	url = {https://doi.org/10.1186/s13007-020-00567-8},
	doi = {10.1186/s13007-020-00567-8},
	abstract = {In this paper, an unsupervised Bayesian learning method is proposed to perform rice panicle segmentation with optical images taken by unmanned aerial vehicles ({UAV}) over paddy fields. Unlike existing supervised learning methods that require a large amount of labeled training data, the unsupervised learning approach detects panicle pixels in {UAV} images by analyzing statistical properties of pixels in an image without a training phase. Under the Bayesian framework, the distributions of pixel intensities are assumed to follow a multivariate Gaussian mixture model ({GMM}), with different components in the {GMM} corresponding to different categories, such as panicle, leaves, or background. The prevalence of each category is characterized by the weights associated with each component in the {GMM}. The model parameters are iteratively learned by using the Markov chain Monte Carlo ({MCMC}) method with Gibbs sampling, without the need of labeled training data.},
	pages = {18},
	number = {1},
	journaltitle = {Plant Methods},
	shortjournal = {Plant Methods},
	author = {Hayat, Md Abul and Wu, Jingxian and Cao, Yingli},
	urldate = {2021-04-24},
	date = {2020-02-22},
	keywords = {Image segmentation, Markov chain Monte Carlo, Multivariate Gaussian mixture model, Plant phenotyping, Rice (O. sativa) panicle, {UAV}, Yield estimation},
	file = {Full Text PDF:/Users/zepingluo/Zotero/storage/GW4L9GMV/Hayat et al. - 2020 - Unsupervised Bayesian learning for rice panicle se.pdf:application/pdf;Snapshot:/Users/zepingluo/Zotero/storage/VKMDRV7Y/s13007-020-00567-8.html:text/html}
}

@online{noauthor_big_nodate,
	title = {Big Five Personality Test {\textbar} Kaggle},
	url = {https://www.kaggle.com/tunguz/big-five-personality-test},
	urldate = {2021-04-24},
	file = {Big Five Personality Test | Kaggle:/Users/zepingluo/Zotero/storage/TU2DXEHI/big-five-personality-test.html:text/html}
}

@online{noauthor_big_2019,
	title = {Big Five Personality Test},
	url = {https://openpsychometrics.org/tests/IPIP-BFFM/},
	titleaddon = {Open-Source Psychometrics Project},
	date = {2019-08-02}
}

@article{ross_dirichletprocess_nodate,
	title = {dirichletprocess: An R Package for Fitting Complex Bayesian Nonparametric Models},
	abstract = {The dirichletprocess package provides software for creating ﬂexible Dirichlet processes objects in R. Users can perform nonparametric Bayesian analysis using Dirichlet processes without the need to program their own inference algorithms. Instead, the user can utilise our pre-built models or specify their own models whilst allowing the dirichletprocess package to handle the Markov chain Monte Carlo sampling. Our Dirichlet process objects can act as building blocks for a variety of statistical models including and not limited to: density estimation, clustering and prior distributions in hierarchical models.},
	pages = {42},
	author = {Ross, Gordon J and Markwick, Dean},
	langid = {english},
	file = {Ross and Markwick - dirichletprocess An R Package for Fitting Complex.pdf:/Users/zepingluo/Zotero/storage/E2CMKJDB/Ross and Markwick - dirichletprocess An R Package for Fitting Complex.pdf:application/pdf}
}

@article{gorur_dirichlet_2010,
	title = {Dirichlet Process Gaussian Mixture Models: Choice of the Base Distribution},
	volume = {25},
	issn = {1000-9000, 1860-4749},
	url = {http://link.springer.com/10.1007/s11390-010-9355-8},
	doi = {10.1007/s11390-010-9355-8},
	shorttitle = {Dirichlet Process Gaussian Mixture Models},
	abstract = {In the Bayesian mixture modeling framework it is possible to infer the necessary number of components to model the data and therefore it is unnecessary to explicitly restrict the number of components. Nonparametric mixture models sidestep the problem of ﬁnding the “correct” number of mixture components by assuming inﬁnitely many components. In this paper Dirichlet process mixture ({DPM}) models are cast as inﬁnite mixture models and inference using Markov chain Monte Carlo is described. The speciﬁcation of the priors on the model parameters is often guided by mathematical and practical convenience. The primary goal of this paper is to compare the choice of conjugate and non-conjugate base distributions on a particular class of {DPM} models which is widely used in applications, the Dirichlet process Gaussian mixture model ({DPGMM}). We compare computational eﬃciency and modeling performance of {DPGMM} deﬁned using a conjugate and a conditionally conjugate base distribution. We show that better density models can result from using a wider class of priors with no or only a modest increase in computational eﬀort.},
	pages = {653--664},
	number = {4},
	journaltitle = {Journal of Computer Science and Technology},
	shortjournal = {J. Comput. Sci. Technol.},
	author = {Görür, Dilan and Edward Rasmussen, Carl},
	urldate = {2021-04-24},
	date = {2010-07},
	langid = {english},
	file = {Görür and Edward Rasmussen - 2010 - Dirichlet Process Gaussian Mixture Models Choice .pdf:/Users/zepingluo/Zotero/storage/HBAFIWV2/Görür and Edward Rasmussen - 2010 - Dirichlet Process Gaussian Mixture Models Choice .pdf:application/pdf}
}
